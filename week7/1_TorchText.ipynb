{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchtext\n",
    "from konlpy.tag import Kkma\n",
    "from torchtext.data import Field,Iterator,Example, TabularDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://mlexplained.com/2018/02/08/a-comprehensive-tutorial-to-torchtext/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchtext.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/torchtext.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Field 선언 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Field는 데이터의 전처리 파이프라인을 정의하는 클래스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://torchtext.readthedocs.io/en/latest/data.html#field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문장 - 클래스 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tagger = Kkma()\n",
    "tokenize = tagger.morphs\n",
    "\n",
    "# tokenize => 함수를 넘겨줘야함\n",
    "TEXT = Field(tokenize=tokenize,use_vocab=True,lower=True, include_lengths=False, batch_first=True) \n",
    "LABEL = Field(sequential=False,unk_token=None, use_vocab=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data, test_data = TabularDataset.splits(\n",
    "                                   path=\"data/\", # 데이터가 있는 root 경로\n",
    "                                   train='train.txt', validation=\"test.txt\",\n",
    "                                   format='tsv', # \\t로 구분\n",
    "                                   #skip_header=True, # 헤더가 있다면 스킵\n",
    "                                   fields=[('inputs',TEXT),('targets',LABEL)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_example = train_data.examples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vocabulary 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FOOD', 'MEDIA']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.itos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Iterator 선언 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.data.dataset.TabularDataset at 0x7f33cc420f28>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.data.dataset.TabularDataset at 0x7f33cc57e748>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make iterator for splits\n",
    "train_iter, test_iter = Iterator.splits(\n",
    "    (train_data, test_data), batch_size=3, device=-1, # device -1 : cpu, device 0 : 남는 gpu\n",
    "    sort_key=lambda x: len(x.inputs),sort_within_batch=True,repeat=False) # x.TEXT 길이 기준으로 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad>'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "   59    75   113     2    67    20    63    10\n",
      "   95    73     9    12    17    16     1     1\n",
      "   15    31    41     4     1     1     1     1\n",
      "[torch.LongTensor of size 3x8]\n",
      "\n",
      "Variable containing:\n",
      " 1\n",
      " 0\n",
      " 1\n",
      "[torch.LongTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iter:\n",
    "    print(batch.inputs)\n",
    "    print(batch.targets)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modeling and Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EmbedClassifier(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_size,output_size):\n",
    "        super(EmbedClassifier,self).__init__()\n",
    "        \n",
    "        # 각 단어의 임베딩을 평균해서 문장 단위의 임베딩 표현\n",
    "        self.sentence_embed = nn.EmbeddingBag(vocab_size,embedding_size)\n",
    "        self.linear = nn.Linear(embedding_size,output_size)\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        outputs = self.sentence_embed(inputs)\n",
    "        outputs = self.linear(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STEP=50\n",
    "LR = 0.1\n",
    "\n",
    "model = EmbedClassifier(len(TEXT.vocab),30,2)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7632251190287727\n",
      "0.4217357113957405\n",
      "0.2671015997018133\n",
      "0.16162016548748528\n",
      "0.10611527439739023\n"
     ]
    }
   ],
   "source": [
    "for step in range(STEP):\n",
    "    losses=[]\n",
    "    for i,batch in enumerate(train_iter):\n",
    "        inputs,lengths = batch.TEXT\n",
    "        targets = batch.LABEL\n",
    "        model.zero_grad()\n",
    "        preds = model(inputs)\n",
    "        loss = loss_function(preds,targets)\n",
    "        losses.append(loss.data[0])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if step % 10==0:\n",
    "        print(np.mean(losses))\n",
    "        losses=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파라미터를 학습하기에 데이터수가 너무 적음..!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 FOOD\n",
      "0 FOOD\n",
      "0 MEDIA\n",
      "0 MEDIA\n"
     ]
    }
   ],
   "source": [
    "for test in test_data.examples:\n",
    "    input, length = TEXT.numericalize(([test.TEXT],[len(test.TEXT)]),train=False,device=-1)\n",
    "    pred = model(input)\n",
    "    pred = pred.max(1)[1]\n",
    "    print(pred.data[0],test.LABEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numericalize "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문장 ==> 인덱스에 맞는 Variable(LongTensor)로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "     0     0     0     0    20    12     0\n",
       " [torch.LongTensor of size 1x7], \n",
       "  7\n",
       " [torch.LongTensor of size 1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.numericalize(([test.TEXT],[len(test.TEXT)]),train=False,device=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
