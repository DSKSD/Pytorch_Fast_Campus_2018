{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as vdatasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "DATA_PATH = os.environ['DATA_PATH']\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyper Parameters \n",
    "INPUT_SIZE = 784\n",
    "HIDDEN_SIZE = 256\n",
    "LATENT_SIZE = 5\n",
    "EPOCH = 50\n",
    "BATCH_SIZE = 100\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MNIST Dataset (Images and Labels)\n",
    "train_dataset = vdatasets.MNIST(root=DATA_PATH+'MNIST/', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "# Dataset Loader (Input Pipline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=BATCH_SIZE, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self,input_size=784,hidden_size=256,z_size=5):\n",
    "        super(VAE,self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, z_size*2))\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(z_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, input_size),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        \"\"\"z = mu + e*sigma\"\"\"\n",
    "        eps = Variable(torch.randn(mu.size()))\n",
    "        z = mu + eps * torch.exp(log_var/2)  \n",
    "        return z\n",
    "                     \n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu, log_var = torch.chunk(h, 2, dim=1)  # mean and log variance.\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        out = self.decoder(z)\n",
    "        return out, mu, log_var\n",
    "    \n",
    "    def sample(self, z):\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kl_divergence(mu,log_var):\n",
    "    \"\"\"0.5 * sum(mu^2 + sigma^2 - log(sigma^2) - 1)\"\"\"\n",
    "    return torch.sum(0.5 * (mu**2 + torch.exp(log_var) - log_var -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = VAE()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/50], Step: [300/600], Loss: 14534.5625\n",
      "Epoch: [1/50], Step: [600/600], Loss: 14141.9502\n",
      "Epoch: [2/50], Step: [300/600], Loss: 14035.9502\n",
      "Epoch: [2/50], Step: [600/600], Loss: 14169.2617\n",
      "Epoch: [3/50], Step: [300/600], Loss: 12949.2588\n",
      "Epoch: [3/50], Step: [600/600], Loss: 13195.1641\n",
      "Epoch: [4/50], Step: [300/600], Loss: 12888.3311\n",
      "Epoch: [4/50], Step: [600/600], Loss: 12215.9219\n",
      "Epoch: [5/50], Step: [300/600], Loss: 13456.4326\n",
      "Epoch: [5/50], Step: [600/600], Loss: 12825.9834\n",
      "Epoch: [6/50], Step: [300/600], Loss: 12109.8223\n",
      "Epoch: [6/50], Step: [600/600], Loss: 12859.3330\n",
      "Epoch: [7/50], Step: [300/600], Loss: 12437.1621\n",
      "Epoch: [7/50], Step: [600/600], Loss: 13290.8232\n",
      "Epoch: [8/50], Step: [300/600], Loss: 11767.6982\n",
      "Epoch: [8/50], Step: [600/600], Loss: 12842.3340\n",
      "Epoch: [9/50], Step: [300/600], Loss: 13385.4141\n",
      "Epoch: [9/50], Step: [600/600], Loss: 13035.7988\n",
      "Epoch: [10/50], Step: [300/600], Loss: 12365.8164\n",
      "Epoch: [10/50], Step: [600/600], Loss: 12731.2178\n",
      "Epoch: [11/50], Step: [300/600], Loss: 12754.0156\n",
      "Epoch: [11/50], Step: [600/600], Loss: 12167.7559\n",
      "Epoch: [12/50], Step: [300/600], Loss: 12073.6533\n",
      "Epoch: [12/50], Step: [600/600], Loss: 12235.6357\n",
      "Epoch: [13/50], Step: [300/600], Loss: 12373.6895\n",
      "Epoch: [13/50], Step: [600/600], Loss: 11798.4160\n",
      "Epoch: [14/50], Step: [300/600], Loss: 11986.5879\n",
      "Epoch: [14/50], Step: [600/600], Loss: 12564.2754\n",
      "Epoch: [15/50], Step: [300/600], Loss: 11790.4053\n",
      "Epoch: [15/50], Step: [600/600], Loss: 12662.0283\n",
      "Epoch: [16/50], Step: [300/600], Loss: 13096.0566\n",
      "Epoch: [16/50], Step: [600/600], Loss: 12705.3613\n",
      "Epoch: [17/50], Step: [300/600], Loss: 12015.9854\n",
      "Epoch: [17/50], Step: [600/600], Loss: 12271.7451\n",
      "Epoch: [18/50], Step: [300/600], Loss: 11761.8770\n",
      "Epoch: [18/50], Step: [600/600], Loss: 12780.1240\n",
      "Epoch: [19/50], Step: [300/600], Loss: 13322.1377\n",
      "Epoch: [19/50], Step: [600/600], Loss: 12379.0391\n",
      "Epoch: [20/50], Step: [300/600], Loss: 12140.5127\n",
      "Epoch: [20/50], Step: [600/600], Loss: 12006.9873\n",
      "Epoch: [21/50], Step: [300/600], Loss: 11898.8828\n",
      "Epoch: [21/50], Step: [600/600], Loss: 12461.0898\n",
      "Epoch: [22/50], Step: [300/600], Loss: 11949.6865\n",
      "Epoch: [22/50], Step: [600/600], Loss: 13216.1299\n",
      "Epoch: [23/50], Step: [300/600], Loss: 13035.0801\n",
      "Epoch: [23/50], Step: [600/600], Loss: 12179.1670\n",
      "Epoch: [24/50], Step: [300/600], Loss: 12307.4746\n",
      "Epoch: [24/50], Step: [600/600], Loss: 11839.5605\n",
      "Epoch: [25/50], Step: [300/600], Loss: 12263.1572\n",
      "Epoch: [25/50], Step: [600/600], Loss: 12157.8760\n",
      "Epoch: [26/50], Step: [300/600], Loss: 11589.5176\n",
      "Epoch: [26/50], Step: [600/600], Loss: 11938.0898\n",
      "Epoch: [27/50], Step: [300/600], Loss: 12474.6904\n",
      "Epoch: [27/50], Step: [600/600], Loss: 11565.0146\n",
      "Epoch: [28/50], Step: [300/600], Loss: 12386.6162\n",
      "Epoch: [28/50], Step: [600/600], Loss: 12706.6914\n",
      "Epoch: [29/50], Step: [300/600], Loss: 11841.9883\n",
      "Epoch: [29/50], Step: [600/600], Loss: 11862.4004\n",
      "Epoch: [30/50], Step: [300/600], Loss: 12617.3311\n",
      "Epoch: [30/50], Step: [600/600], Loss: 10980.4131\n",
      "Epoch: [31/50], Step: [300/600], Loss: 11788.8857\n",
      "Epoch: [31/50], Step: [600/600], Loss: 12160.9824\n",
      "Epoch: [32/50], Step: [300/600], Loss: 11964.6455\n",
      "Epoch: [32/50], Step: [600/600], Loss: 12007.4023\n",
      "Epoch: [33/50], Step: [300/600], Loss: 12590.1191\n",
      "Epoch: [33/50], Step: [600/600], Loss: 12169.3301\n",
      "Epoch: [34/50], Step: [300/600], Loss: 11979.3623\n",
      "Epoch: [34/50], Step: [600/600], Loss: 12510.7051\n",
      "Epoch: [35/50], Step: [300/600], Loss: 11960.3789\n",
      "Epoch: [35/50], Step: [600/600], Loss: 10966.9053\n",
      "Epoch: [36/50], Step: [300/600], Loss: 12305.7314\n",
      "Epoch: [36/50], Step: [600/600], Loss: 11985.0957\n",
      "Epoch: [37/50], Step: [300/600], Loss: 12544.9170\n",
      "Epoch: [37/50], Step: [600/600], Loss: 12167.2520\n",
      "Epoch: [38/50], Step: [300/600], Loss: 12599.9004\n",
      "Epoch: [38/50], Step: [600/600], Loss: 12008.9014\n",
      "Epoch: [39/50], Step: [300/600], Loss: 11923.9580\n",
      "Epoch: [39/50], Step: [600/600], Loss: 12566.7139\n",
      "Epoch: [40/50], Step: [300/600], Loss: 11865.6777\n",
      "Epoch: [40/50], Step: [600/600], Loss: 11889.8818\n",
      "Epoch: [41/50], Step: [300/600], Loss: 11408.3125\n",
      "Epoch: [41/50], Step: [600/600], Loss: 11794.0576\n",
      "Epoch: [42/50], Step: [300/600], Loss: 12447.9150\n",
      "Epoch: [42/50], Step: [600/600], Loss: 12709.4688\n",
      "Epoch: [43/50], Step: [300/600], Loss: 12313.0576\n",
      "Epoch: [43/50], Step: [600/600], Loss: 12101.0889\n",
      "Epoch: [44/50], Step: [300/600], Loss: 11796.0781\n",
      "Epoch: [44/50], Step: [600/600], Loss: 12387.5459\n",
      "Epoch: [45/50], Step: [300/600], Loss: 12467.4863\n",
      "Epoch: [45/50], Step: [600/600], Loss: 12427.1328\n",
      "Epoch: [46/50], Step: [300/600], Loss: 11924.9619\n",
      "Epoch: [46/50], Step: [600/600], Loss: 12166.0957\n",
      "Epoch: [47/50], Step: [300/600], Loss: 11440.4707\n",
      "Epoch: [47/50], Step: [600/600], Loss: 11956.2539\n",
      "Epoch: [48/50], Step: [300/600], Loss: 11729.7764\n",
      "Epoch: [48/50], Step: [600/600], Loss: 12709.3535\n",
      "Epoch: [49/50], Step: [300/600], Loss: 12835.9365\n",
      "Epoch: [49/50], Step: [600/600], Loss: 11809.5098\n",
      "Epoch: [50/50], Step: [300/600], Loss: 12518.0674\n",
      "Epoch: [50/50], Step: [600/600], Loss: 11787.3867\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(EPOCH):\n",
    "    for i, (inputs, _) in enumerate(train_loader):\n",
    "        inputs = Variable(inputs.view(-1, 28*28))\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        recon, mu, log_var = model(inputs)\n",
    "        loss = F.binary_cross_entropy(recon, inputs,size_average=False) + kl_divergence(mu,log_var)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 300 == 0:\n",
    "            print ('Epoch: [%d/%d], Step: [%d/%d], Loss: %.4f' \n",
    "                   % (epoch+1, EPOCH, i+1, len(train_dataset)//BATCH_SIZE, loss.data[0]))\n",
    "            \n",
    "# 생성 이미지 샘플 저장\n",
    "normal = Variable(torch.randn(50,LATENT_SIZE)) # p(z)\n",
    "sampled_image = model.sample(normal)\n",
    "sampled_image = sampled_image.view(50,1,28,28)\n",
    "save_image(sampled_image.data, './images/vae_gen_images.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAEFCAYAAADjfVLrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAbOKcxAwqzgHAbOKcxAwq7j/D8sx+yO5yxvLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faf0c112c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = Variable(torch.randn(1,5)) #  z ~ p(z)\n",
    "image = model.sample(z)\n",
    "\n",
    "plt.matshow(np.reshape(image.data.numpy(), (28, 28)), cmap=plt.get_cmap('gray'))\n",
    "plt.title(\"[\" + str(epoch) + \"] Generated Image\\n\")\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
