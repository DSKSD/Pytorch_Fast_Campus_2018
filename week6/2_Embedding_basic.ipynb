{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import nltk\n",
    "from torchtext.data import Field, Iterator\n",
    "from konlpy.tag import Kkma\n",
    "kor_tagger = Kkma()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Word Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pytorch = torch.Tensor([0.6,-0.2,0.7,0.3,0.7,-0.2,0.1,0.1])\n",
    "tensorflow = torch.Tensor([0.4,-0.1,0.6,-0.2,0.6,-0.2,0.3,0.4])\n",
    "cat = torch.Tensor([-0.3,0.2,0.1,0.2,-0.2,0.1,-0.3,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1500000953674316"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch.dot(tensorflow) # inner product = word similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.26999998092651367"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch.dot(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.8417\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cosine_similarity(pytorch.view(1,-1),tensorflow.view(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-0.3800\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cosine_similarity(pytorch.view(1,-1),cat.view(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Embedding() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "-0.6793  0.4472 -0.9793 -0.8395 -0.6814\n",
       "-0.4536 -2.4421 -0.1348  0.9971 -0.5014\n",
       "-1.6717  1.4754 -0.5612  0.5028 -1.0438\n",
       " 0.5872  0.2038  0.3458  1.2999  0.5597\n",
       " 0.5389  0.0836 -0.5558  1.7882 -2.0546\n",
       "-0.9809  1.1761  0.0456  0.2127 -2.3012\n",
       " 0.0745  0.2277  0.0131  1.1204 -0.6464\n",
       "[torch.FloatTensor of size 7x5]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = nn.Embedding(7,5) # 총 단어 갯수, 임베딩 시킬 차원\n",
    "embed.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.6793  0.4472 -0.9793 -0.8395 -0.6814\n",
       "[torch.FloatTensor of size 1x5]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple = torch.LongTensor([0]) # 0은 사과의 인덱스\n",
    "embed(Variable(apple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.4536 -2.4421 -0.1348  0.9971 -0.5014\n",
       " 0.5872  0.2038  0.3458  1.2999  0.5597\n",
       "-0.9809  1.1761  0.0456  0.2127 -2.3012\n",
       "[torch.FloatTensor of size 3x5]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = torch.LongTensor([1,3,5]) # 단어의 시퀀스(문장)\n",
    "embed(Variable(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.EmbeddingBag "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 워드 벡터를 합하거나 평균해서 하나의 벡터를 반환 ==> Sentence Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.2805 -0.6985  0.1718  0.0476  0.3264\n",
       "[torch.FloatTensor of size 1x5]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_sum = nn.EmbeddingBag(7, 5, mode='mean')\n",
    "sentence = Variable(torch.LongTensor([[1,3,5]])) # 토큰 1,3,5로 이루어진 문장\n",
    "embedding_sum(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다음의 코퍼스를 형태소로 tokenize하고 Vocabulary를 구축하라(Word2index)\n",
    "- 각 단어를 10차원으로 임베딩하기 위한 nn.Embedding을 선언하라\n",
    "- \"토치\"와 \"텐서플로우\"라는 단어를 Embedding matrix에서 읽어서 두 벡터를 내적하라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [\"안녕하세요 저는 파이토치를 공부중입니다.\",\"파이토치는 딥러닝 라이브러리이다\", \"파이토치와 유사한 것으로 텐서플로우와 케라스 등이 있다\",\n",
    "         \"파이토치는 정말 쉽다\",\"텐서플로우는 구글이 만들었다\",\"페북에서는 파이토치를 만들었다\", \"파이썬과 쉽게 사용할 수 있는 것이 장점이다\",\n",
    "         \"그 중 특히 자연어처리할 때 파이토치가 좋다\",\"하지만 아직 베타 버전인게 파이토치의 단점이다\",\"원래는 루아라는 언어로 만들어진 토치라는 프레임워크였다\",\n",
    "         \"텐서플로우나 파이토치는 자동미분 기능을 제공한다\", \"이를 이용하면 딥러닝 모델을 쉽게 만들 수 있다\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
