{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* http://pytorch.org/docs/master/\n",
    "* https://github.com/rguthrie3/DeepLearningForNLPInPytorch\n",
    "* https://github.com/yunjey/pytorch-tutorial\n",
    "* https://github.com/hunkim/PyTorchZeroToAll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. What is a Pytorch? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서와 옵티마이저, 뉴럴넷 등 GPU 연산에 최적화된 모듈을 이용하여 빠르게 <strong>딥러닝 모델을 구현할 수 있는 프레임워크</strong> <br>\n",
    "Facebook이 밀고 있던 lua 기반의 torch를 python 버전으로 포팅함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. What is difference between Pytorch and Tensorflow? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://medium.com/towards-data-science/pytorch-vs-tensorflow-spotting-the-difference-25c75777377b\n",
    "* http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture8.pdf\n",
    "* https://devblogs.nvidia.com/parallelforall/recursive-neural-networks-pytorch/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=revue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Why Pytorch? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pythonic \n",
    "* Easy debugging\n",
    "* Intuitive => Easy to understand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1> Pytorch Basic "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tensor\n",
    "* Variable\n",
    "* Module\n",
    "* Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이토치의 가장 기본 단위는 Tensor이다. 디폴트 Tensor는 FloatTensor이고, LongTensor, ByteTensor, 등 여러 종류가 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이썬 리스트로부터 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1\n",
      " 2\n",
      " 3\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "\n",
      " 1  2  3\n",
      " 4  5  6\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "\n",
      "(0 ,.,.) = \n",
      "  1  2\n",
      "  3  4\n",
      "\n",
      "(1 ,.,.) = \n",
      "  5  6\n",
      "  7  8\n",
      "[torch.FloatTensor of size 2x2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "V_data = [1., 2., 3.] # 벡터\n",
    "V = torch.Tensor(V_data) \n",
    "print(V)\n",
    "\n",
    "M_data = [[1., 2., 3.], [4., 5., 6]] # 매트릭스\n",
    "M = torch.Tensor(M_data)\n",
    "print(M)\n",
    "\n",
    "T_data = [[[1.,2.], [3.,4.]], # 3차원 텐서\n",
    "          [[5.,6.], [7.,8.]]]\n",
    "T = torch.Tensor(T_data)\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1.0, 2.0], [3.0, 4.0]], [[5.0, 6.0], [7.0, 8.0]]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.tolist() # 반대로 파이토치 텐서 -> 파이썬 리스트로 꺼내오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### numpy ndarray 객체로부터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1\n",
      " 2\n",
      " 3\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "\n",
      " 1  2  3\n",
      " 4  5  6\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "\n",
      "(0 ,.,.) = \n",
      "  1  2\n",
      "  3  4\n",
      "\n",
      "(1 ,.,.) = \n",
      "  5  6\n",
      "  7  8\n",
      "[torch.FloatTensor of size 2x2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "V_data = np.array([1.,2.,3.])# 벡터\n",
    "V = torch.Tensor(V_data) # 파이썬의 리스트를 바로 랩핑할 수 있다.\n",
    "print(V)\n",
    "\n",
    "M_data = np.array([[1., 2., 3.], [4., 5., 6]]) # 매트릭스\n",
    "M = torch.Tensor(M_data)\n",
    "print(M)\n",
    "\n",
    "T_data = np.array([[[1.,2.], [3.,4.]], # 3차원 텐서\n",
    "          [[5.,6.], [7.,8.]]])\n",
    "T = torch.Tensor(T_data)\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.,  2.],\n",
       "        [ 3.,  4.]],\n",
       "\n",
       "       [[ 5.,  6.],\n",
       "        [ 7.,  8.]]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.numpy() # 반대로 파이토치 텐서 -> 넘파이로 꺼내오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기타 다른 생성 방법들 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0  0  0\n",
      " 0  0  0\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "\n",
      " 1  1  1\n",
      " 1  1  1\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "\n",
      " 0.1769  0.8206  0.6776  0.6237\n",
      " 0.4009  0.3440  0.5848  0.8869\n",
      " 0.5716  0.2636  0.9967  0.5107\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "\n",
      " 0.6964  1.1296  0.2214 -0.0558\n",
      " 1.2057  1.9486 -0.0766 -0.8562\n",
      "-0.7870 -0.8161  0.5470 -1.1707\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "\n",
      " 3\n",
      " 4\n",
      " 1\n",
      " 0\n",
      " 2\n",
      "[torch.LongTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(2,3)\n",
    "print(x)\n",
    "\n",
    "x = torch.ones(2,3)\n",
    "print(x)\n",
    "\n",
    "x = torch.rand(3,4)\n",
    "print(x)\n",
    "\n",
    "x = torch.randn(3, 4) # 표준정규분포에서 샘플링\n",
    "print(x) # FloatTensor가 디폴트\n",
    "\n",
    "x = torch.randperm(5) # permutation of integers from 0 to n - 1\n",
    "print(x) # LongTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Indexing, Slicing, Joining, Mutating Ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://pytorch.org/docs/0.3.0/torch.html?#indexing-slicing-joining-mutating-ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.randn(3, 4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-0.1127  1.5980 -0.8445 -1.0489  0.9387\n",
       " 0.5378  1.5372 -0.6943  0.2174 -0.2995\n",
       "-0.3749  1.8673  0.9042  0.1181  1.8941\n",
       "-0.4229  0.7431  0.0756  1.1366 -1.9280\n",
       "[torch.FloatTensor of size 4x5]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0] # 직관적(파이써닉한) 인덱싱 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-0.1127\n",
       " 1.5980\n",
       "-0.8445\n",
       "-1.0489\n",
       " 0.9387\n",
       "[torch.FloatTensor of size 5]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.11267814040184021"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.select_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.3255 -0.4791  1.3790  2.5286\n",
      " 0.4107 -0.9880 -0.9081  0.5423\n",
      " 0.1103 -2.2590  0.6067 -0.1383\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "\n",
      " 0\n",
      " 2\n",
      "[torch.LongTensor of size 2]\n",
      "\n",
      "\n",
      " 0.3255 -0.4791  1.3790  2.5286\n",
      " 0.1103 -2.2590  0.6067 -0.1383\n",
      "[torch.FloatTensor of size 2x4]\n",
      "\n",
      "\n",
      " 0.3255  1.3790\n",
      " 0.4107 -0.9081\n",
      " 0.1103  0.6067\n",
      "[torch.FloatTensor of size 3x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 4)\n",
    "print(x)\n",
    "\n",
    "indices = torch.LongTensor([0, 2])\n",
    "print(indices) # 선택할 index (LongTensor)\n",
    "\n",
    "print(torch.index_select(x, 0, indices)) # row 기준 select index\n",
    "\n",
    "print(torch.index_select(x, 1, indices)) # column 기준 select index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.masked_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.8310 -0.2477 -0.8029  0.2366\n",
      " 0.2857  0.6898 -0.6331  0.8795\n",
      "-0.6842  0.4533  0.2912 -0.8317\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "\n",
      " 1  0  0  0\n",
      " 0  1  0  1\n",
      " 0  0  0  0\n",
      "[torch.ByteTensor of size 3x4]\n",
      "\n",
      "\n",
      " 0.8310\n",
      " 0.6898\n",
      " 0.8795\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 4)\n",
    "print(x)\n",
    "\n",
    "mask = x.ge(0.5) # x 텐서에서 0.5보다 크거나 같은값 마스킹 (ByteTensor)\n",
    "print(mask) \n",
    "\n",
    "print(torch.masked_select(x, mask)) # 마스킹 된 값 선택하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.cat => concat : 두 텐서를 붙인다(Concatenation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-2.5667 -1.4303  0.5009  0.5438 -0.4057\n",
      " 1.1341 -1.1115  0.3501 -0.7703 -0.1473\n",
      " 0.6272  1.0935  0.0939  1.2381 -1.3459\n",
      " 0.5119 -0.6933 -0.1668 -0.9999 -1.6476\n",
      " 0.8098  0.0554  1.1340 -0.5326  0.6592\n",
      "[torch.FloatTensor of size 5x5]\n",
      "\n",
      "\n",
      "-1.5964 -0.3769 -3.1020 -0.0020 -1.0952  0.6016  0.6984 -0.8005\n",
      "-0.0995 -0.7213  1.2708  1.5381  1.4673  1.5951 -1.5279  1.0156\n",
      "[torch.FloatTensor of size 2x8]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# row-wise concat\n",
    "x_1 = torch.randn(2, 5)\n",
    "y_1 = torch.randn(3, 5)\n",
    "z_1 =torch.cat([x_1, y_1]) # 디폴트는 첫번째 차원 기준으로 콘캣 (0)\n",
    "print(z_1)\n",
    "\n",
    "# column-wise concat\n",
    "x_2 = torch.randn(2, 3)\n",
    "y_2 = torch.randn(2, 5)\n",
    "z_2 = torch.cat([x_2, y_2], 1) # 두번째 인자로 콘캣할 차원축을 선택할 수 있다.\n",
    "print(z_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.view => reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0 ,.,.) = \n",
      " -0.2020 -1.2865  0.8231 -0.6101\n",
      " -1.2960 -0.9434  0.6684  1.1628\n",
      " -0.3229  1.8782 -0.5666  0.4016\n",
      "\n",
      "(1 ,.,.) = \n",
      " -0.1153  0.3170  0.5629  0.8662\n",
      " -0.3528  0.3482  1.1371 -0.3339\n",
      " -1.4724  0.7296 -0.1312 -0.6368\n",
      "[torch.FloatTensor of size 2x3x4]\n",
      "\n",
      "\n",
      "\n",
      "Columns 0 to 9 \n",
      "-0.2020 -1.2865  0.8231 -0.6101 -1.2960 -0.9434  0.6684  1.1628 -0.3229  1.8782\n",
      "-0.1153  0.3170  0.5629  0.8662 -0.3528  0.3482  1.1371 -0.3339 -1.4724  0.7296\n",
      "\n",
      "Columns 10 to 11 \n",
      "-0.5666  0.4016\n",
      "-0.1312 -0.6368\n",
      "[torch.FloatTensor of size 2x12]\n",
      "\n",
      "\n",
      "\n",
      "Columns 0 to 9 \n",
      "-0.2020 -1.2865  0.8231 -0.6101 -1.2960 -0.9434  0.6684  1.1628 -0.3229  1.8782\n",
      "-0.1153  0.3170  0.5629  0.8662 -0.3528  0.3482  1.1371 -0.3339 -1.4724  0.7296\n",
      "\n",
      "Columns 10 to 11 \n",
      "-0.5666  0.4016\n",
      "-0.1312 -0.6368\n",
      "[torch.FloatTensor of size 2x12]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 4)\n",
    "print(x)\n",
    "print(x.view(2, 12)) # 2x12로 reshape\n",
    "print(x.view(2, -1)) # -1이 들어가면 각 차원을 다 곱한 값에서 명시적인 차원수를 나눠서 추론할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0 ,0 ,.,.) = \n",
      "  0\n",
      "  0\n",
      "\n",
      "(1 ,0 ,.,.) = \n",
      "  0\n",
      "  0\n",
      "[torch.FloatTensor of size 2x1x2x1]\n",
      "\n",
      "\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "\n",
      "(0 ,.,.) = \n",
      "  0\n",
      "  0\n",
      "\n",
      "(1 ,.,.) = \n",
      "  0\n",
      "  0\n",
      "[torch.FloatTensor of size 2x2x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(2,1,2,1)\n",
    "print(x)\n",
    "print(x.squeeze()) # 차원의 사이즈가 1인 차원을 제거한다\n",
    "print(x.squeeze(1)) # 차원수 명시 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.unsqueeze  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-0.7703\n",
      "-0.1473\n",
      " 0.6272\n",
      " 1.0935\n",
      " 0.0939\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "\n",
      "-0.7703 -0.1473  0.6272  1.0935  0.0939\n",
      "[torch.FloatTensor of size 1x5]\n",
      "\n",
      "\n",
      "-0.7703\n",
      "-0.1473\n",
      " 0.6272\n",
      " 1.0935\n",
      " 0.0939\n",
      "[torch.FloatTensor of size 5x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(5)\n",
    "print(x)\n",
    "\n",
    "print(x.unsqueeze(0)) # squeeze의 반대, 사이즈가 1인 차원을 추가한다\n",
    "print(x.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Math operation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://pytorch.org/docs/0.3.0/torch.html?#math-operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 5\n",
      " 7\n",
      " 9\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "\n",
      " 5\n",
      " 7\n",
      " 9\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([ 1., 2., 3. ])\n",
    "y = torch.Tensor([ 4., 5., 6. ])\n",
    "z = x + y # torch.add(x,y)\n",
    "print(z)\n",
    "print(torch.add(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([ 1., 2., 3. ])\n",
    "print(x.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dot product "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.0\n",
      "32.0\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([ 1., 2., 3. ])\n",
    "y = torch.Tensor([ 4., 5., 6. ])\n",
    "z = x.dot(y) # torch.dot(x,y)\n",
    "print(z)\n",
    "print(torch.dot(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mul "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  4\n",
      " 10\n",
      " 18\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([ 1., 2., 3. ])\n",
    "y = torch.Tensor([ 4., 5., 6. ])\n",
    "z = x.mul(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mm: matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.0504  1.2295 -0.1465\n",
      " 0.1589  0.8862 -0.3472\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,2)\n",
    "y = torch.randn(2,3)\n",
    "z = x.mm(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "(\n",
      " 2\n",
      " 4\n",
      "[torch.FloatTensor of size 2]\n",
      ", \n",
      " 1\n",
      " 1\n",
      "[torch.LongTensor of size 2]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1.,2.],[3.,4.]])\n",
    "print(x.max())\n",
    "print(x.max(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Computation Graphs and Automatic Differentiation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝 프레임워크의 가장 큰 장점인 자동 미분 기능을 사용하기 위해서는 Variable, Parameter 클래스로 래핑해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1\n",
      " 2\n",
      " 3\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "\n",
      " 5\n",
      " 7\n",
      " 9\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "<AddBackward1 object at 0x7fc244c68198>\n"
     ]
    }
   ],
   "source": [
    "# Variable은 텐서를 래핑한다 (autograd 기능에 의한 미분값의 필요여부 결정할 수 있음)\n",
    "x = Variable( torch.Tensor([1., 2., 3]), requires_grad=True )\n",
    "\n",
    "# Variable로 감싸준 상태에서 .data로 원래 텐서에 접근할 수 있다 \n",
    "print(x.data)\n",
    "\n",
    "# 역시 Variable로 래핑한 다른 텐서들과 연산할 수 있다\n",
    "y = Variable( torch.Tensor([4., 5., 6]), requires_grad=True )\n",
    "z = x + y\n",
    "print(z.data)\n",
    "\n",
    "# 하지만 연산의 결과인 z는 뭔가 추가적인 정보를 알고 있다!\n",
    "print(z.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 21\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "<SumBackward0 object at 0x7fc244c6d3c8>\n"
     ]
    }
   ],
   "source": [
    "s = z.sum()\n",
    "print(s)\n",
    "print(s.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s.backward() # 이 값으로부터 backpropagation을 하고 싶다면 .backward()를 call하면 됨\n",
    "print(x.grad) # x의 gradient가 계산되었음!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ s = \\overbrace{x_0 + y_0}^\\text{$z_0$} + \\overbrace{x_1 + y_1}^\\text{$z_1$} + \\overbrace{x_2 + y_2}^\\text{$z_2$} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{\\partial s}{\\partial x_0} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable vs Parameter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Variable : 학습 및 모델 추론에 필요한 변수\n",
    "- Parameter : 학습을 통해 찾아야 할 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.Tensor([1.,2.,3.])\n",
    "vx = Variable(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vx.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "px = nn.Parameter(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1\n",
      " 2\n",
      " 3\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(px.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "px.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. torch.nn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Linear (Affine Maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ f(x) = Ax + b $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.1755 -0.3268 -0.5069\n",
      "-0.6602  0.2260  0.1089\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lin = nn.Linear(5, 3) # maps from R^5 to R^3, parameters A, b\n",
    "data = Variable( torch.randn(2, 5) ) \n",
    "print(lin(data)) # (2x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 비선형 함수들 (Non-Linearities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-1.0246 -1.0300\n",
      "-1.0129  0.0055\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  0.0000  0.0000\n",
      "  0.0000  5.5350\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "Variable containing:\n",
      "-0.7717 -0.7739\n",
      "-0.7670  0.0055\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "Variable containing:\n",
      " 0.2641  0.2631\n",
      " 0.2664  0.5014\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = Variable( torch.randn(2, 2) )\n",
    "print(data)\n",
    "print(F.relu(data))\n",
    "print(F.tanh(data))\n",
    "print(F.sigmoid(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.9347\n",
      "-0.9882\n",
      " 1.3801\n",
      "-0.1173\n",
      " 0.9317\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "Variable containing:\n",
      " 0.0481\n",
      " 0.0456\n",
      " 0.4867\n",
      " 0.1089\n",
      " 0.3108\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "-3.0350\n",
      "-3.0885\n",
      "-0.7201\n",
      "-2.2176\n",
      "-1.1686\n",
      "[torch.FloatTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Softmax is also in torch.functional\n",
    "data = Variable( torch.randn(5) )\n",
    "print(data)\n",
    "print(F.softmax(data))\n",
    "print(F.softmax(data).sum()) # Sums to 1 because it is a distribution!\n",
    "print(F.log_softmax(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Containers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Module "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이토치는 모델을 클래스처럼 다룰 수 있는데, torch.nn.Module을 상속받아서 부모 클래스를 초기화하는 방법 <br>\n",
    "선정의 된 함수 forward에 Variable을 인자 값으로 보내면 forward 계산을 하면서 Parameter와의 backward 계산을 해서 가지고 있는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class simpleNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(simpleNN, self).__init__() # 부모 클래스까지 초기화(부모 클래스 생성자 호출)\n",
    "        self.linear = nn.Linear(2,2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        return self.sigmoid(self.linear(inputs))\n",
    "#         return F.sigmoid(self.linear(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snn = simpleNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simpleNN(\n",
       "  (linear): Linear(in_features=2, out_features=2)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모듈 파라미터 혹은 서브 모듈에 접근 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      " 0.3026 -0.3286\n",
      " 0.6938 -0.2992\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "Parameter containing:\n",
      " 0.5303\n",
      " 0.0084\n",
      "[torch.FloatTensor of size 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for param in snn.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('linear.weight', Parameter containing:\n",
      " 0.3026 -0.3286\n",
      " 0.6938 -0.2992\n",
      "[torch.FloatTensor of size 2x2]\n",
      ")\n",
      "('linear.bias', Parameter containing:\n",
      " 0.5303\n",
      " 0.0084\n",
      "[torch.FloatTensor of size 2]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for param in snn.named_parameters():\n",
    "    print(param) # (name, Parameter) tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      " 0.3026 -0.3286\n",
      " 0.6938 -0.2992\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for param in snn.named_parameters():\n",
    "    if \"weight\" in param[0]:\n",
    "        print(param[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=2, out_features=2)\n",
      "Sigmoid()\n"
     ]
    }
   ],
   "source": [
    "for child in snn.children():\n",
    "    print(child) # module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### forward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 2.2820 -1.2080\n",
       "[torch.FloatTensor of size 1x2]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = Variable(torch.randn(1,2))\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.1198  0.5264\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = snn(inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Sequential() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "                                 nn.Linear(2,2),\n",
    "                                 nn.Sigmoid()\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.container.Sequential"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=2)\n",
       "  (1): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.7876  0.7099\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = model(inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(OrderedDict([\n",
    "          ('conv1', nn.Conv2d(1,20,5)),\n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('conv2', nn.Conv2d(20,64,5)),\n",
    "          ('relu2', nn.ReLU())\n",
    "        ])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://pytorch.org/docs/0.3.0/nn.html#loss-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(snn.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dampening': 0,\n",
       "  'lr': 0.01,\n",
       "  'momentum': 0,\n",
       "  'nesterov': False,\n",
       "  'params': [Parameter containing:\n",
       "   -0.6167  0.5950\n",
       "   -0.1340  0.1427\n",
       "   [torch.FloatTensor of size 2x2], Parameter containing:\n",
       "    0.0262\n",
       "   -0.4506\n",
       "   [torch.FloatTensor of size 2]],\n",
       "  'weight_decay': 0}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
