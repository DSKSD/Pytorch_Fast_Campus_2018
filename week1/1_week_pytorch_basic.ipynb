{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc29c071250>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* http://pytorch.org/docs/master/\n",
    "* https://github.com/rguthrie3/DeepLearningForNLPInPytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. What is a Pytorch? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서와 옵티마이저, 뉴럴넷 등 GPU 연산에 최적화된 모듈을 이용하여 빠르게 <strong>딥러닝 모델을 구현할 수 있는 프레임워크</strong> <br>\n",
    "Facebook이 밀고 있던 lua 기반의 torch를 python 버전으로 포팅함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. What is difference between Pytorch and Tensorflow? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://medium.com/towards-data-science/pytorch-vs-tensorflow-spotting-the-difference-25c75777377b\n",
    "* http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture8.pdf\n",
    "* https://devblogs.nvidia.com/parallelforall/recursive-neural-networks-pytorch/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=revue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Why Pytorch? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pythonic \n",
    "* Easy debugging\n",
    "* Intuitive => Easy to understand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1> Pytorch Basic "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tensor\n",
    "* Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이토치의 가장 기본 단위는 Tensor이다. 디폴트 Tensor는 FloatTensor이고, LongTensor, ByteTensor, 등 여러 종류가 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 텐서 만들기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1\n",
      " 2\n",
      " 3\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "\n",
      " 1  2  3\n",
      " 4  5  6\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "\n",
      "(0 ,.,.) = \n",
      "  1  2\n",
      "  3  4\n",
      "\n",
      "(1 ,.,.) = \n",
      "  5  6\n",
      "  7  8\n",
      "[torch.FloatTensor of size 2x2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "V_data = [1., 2., 3.] # 벡터\n",
    "V = torch.Tensor(V_data) # 파이썬의 리스트를 바로 랩핑할 수 있다.\n",
    "print(V)\n",
    "\n",
    "M_data = [[1., 2., 3.], [4., 5., 6]] # 매트릭스\n",
    "M = torch.Tensor(M_data)\n",
    "print(M)\n",
    "\n",
    "T_data = [[[1.,2.], [3.,4.]], # 3차원 텐서\n",
    "          [[5.,6.], [7.,8.]]]\n",
    "T = torch.Tensor(T_data)\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "numpy 객체로부터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1\n",
      " 2\n",
      " 3\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "\n",
      " 1  2  3\n",
      " 4  5  6\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "\n",
      "(0 ,.,.) = \n",
      "  1  2\n",
      "  3  4\n",
      "\n",
      "(1 ,.,.) = \n",
      "  5  6\n",
      "  7  8\n",
      "[torch.FloatTensor of size 2x2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "V_data = np.array([1.,2.,3.])# 벡터\n",
    "V = torch.Tensor(V_data) # 파이썬의 리스트를 바로 랩핑할 수 있다.\n",
    "print(V)\n",
    "\n",
    "M_data = np.array([[1., 2., 3.], [4., 5., 6]]) # 매트릭스\n",
    "M = torch.Tensor(M_data)\n",
    "print(M)\n",
    "\n",
    "T_data = np.array([[[1.,2.], [3.,4.]], # 3차원 텐서\n",
    "          [[5.,6.], [7.,8.]]])\n",
    "T = torch.Tensor(T_data)\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0 ,.,.) = \n",
      "  0.6614  0.2669  0.0617  0.6213 -0.4519\n",
      " -0.1661 -1.5228  0.3817 -1.0276 -0.5631\n",
      " -0.8923 -0.0583 -0.1955 -0.9656  0.4224\n",
      "  0.2673 -0.4212 -0.5107 -1.5727 -0.1232\n",
      "\n",
      "(1 ,.,.) = \n",
      "  3.5870 -1.8313  1.5987 -1.2770  0.3255\n",
      " -0.4791  1.3790  2.5286  0.4107 -0.9880\n",
      " -0.9081  0.5423  0.1103 -2.2590  0.6067\n",
      " -0.1383  0.8310 -0.2477 -0.8029  0.2366\n",
      "\n",
      "(2 ,.,.) = \n",
      "  0.2857  0.6898 -0.6331  0.8795 -0.6842\n",
      "  0.4533  0.2912 -0.8317 -0.5525  0.6355\n",
      " -0.3968 -0.6571 -1.6428  0.9803 -0.0421\n",
      " -0.8206  0.3133 -1.1352  0.3773 -0.2824\n",
      "[torch.FloatTensor of size 3x4x5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn((3, 4, 5)) # 3x4x5 텐서를 랜덤으로 초기화하기\n",
    "print(x) # FloatTensor가 디폴트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.6614  0.2669  0.0617  0.6213 -0.4519\n",
       "-0.1661 -1.5228  0.3817 -1.0276 -0.5631\n",
       "-0.8923 -0.0583 -0.1955 -0.9656  0.4224\n",
       " 0.2673 -0.4212 -0.5107 -1.5727 -0.1232\n",
       "[torch.FloatTensor of size 4x5]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0] # indexing도 직관적이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.6614\n",
       " 0.2669\n",
       " 0.0617\n",
       " 0.6213\n",
       "-0.4519\n",
       "[torch.FloatTensor of size 5]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6613521575927734"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 텐서 연산 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 5\n",
      " 7\n",
      " 9\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([ 1., 2., 3. ])\n",
    "y = torch.Tensor([ 4., 5., 6. ])\n",
    "z = x + y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 앞으로 자주 쓰게 될 연산 <strong>cat</strong> => concat : 두 텐서를 연결한다(Concatenation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-2.5667 -1.4303  0.5009  0.5438 -0.4057\n",
      " 1.1341 -1.1115  0.3501 -0.7703 -0.1473\n",
      " 0.6272  1.0935  0.0939  1.2381 -1.3459\n",
      " 0.5119 -0.6933 -0.1668 -0.9999 -1.6476\n",
      " 0.8098  0.0554  1.1340 -0.5326  0.6592\n",
      "[torch.FloatTensor of size 5x5]\n",
      "\n",
      "\n",
      "-1.5964 -0.3769 -3.1020 -0.0020 -1.0952  0.6016  0.6984 -0.8005\n",
      "-0.0995 -0.7213  1.2708  1.5381  1.4673  1.5951 -1.5279  1.0156\n",
      "[torch.FloatTensor of size 2x8]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# By default, it concatenates along the first axis (concatenates rows)\n",
    "x_1 = torch.randn(2, 5)\n",
    "y_1 = torch.randn(3, 5)\n",
    "z_1 =torch.cat([x_1, y_1]) # 디폴트는 첫번째 차원 기준으로 콘캣 (0)\n",
    "print(z_1)\n",
    "\n",
    "# Concatenate columns:\n",
    "x_2 = torch.randn(2, 3)\n",
    "y_2 = torch.randn(2, 5)\n",
    "z_2 = torch.cat([x_2, y_2], 1) # 두번째 인자로 콘캣할 차원축을 선택할 수 있다.\n",
    "print(z_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 앞으로 자주 쓰게 될 연산 <strong>view</strong> => reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0 ,.,.) = \n",
      " -0.2020 -1.2865  0.8231 -0.6101\n",
      " -1.2960 -0.9434  0.6684  1.1628\n",
      " -0.3229  1.8782 -0.5666  0.4016\n",
      "\n",
      "(1 ,.,.) = \n",
      " -0.1153  0.3170  0.5629  0.8662\n",
      " -0.3528  0.3482  1.1371 -0.3339\n",
      " -1.4724  0.7296 -0.1312 -0.6368\n",
      "[torch.FloatTensor of size 2x3x4]\n",
      "\n",
      "\n",
      "\n",
      "Columns 0 to 9 \n",
      "-0.2020 -1.2865  0.8231 -0.6101 -1.2960 -0.9434  0.6684  1.1628 -0.3229  1.8782\n",
      "-0.1153  0.3170  0.5629  0.8662 -0.3528  0.3482  1.1371 -0.3339 -1.4724  0.7296\n",
      "\n",
      "Columns 10 to 11 \n",
      "-0.5666  0.4016\n",
      "-0.1312 -0.6368\n",
      "[torch.FloatTensor of size 2x12]\n",
      "\n",
      "\n",
      "\n",
      "Columns 0 to 9 \n",
      "-0.2020 -1.2865  0.8231 -0.6101 -1.2960 -0.9434  0.6684  1.1628 -0.3229  1.8782\n",
      "-0.1153  0.3170  0.5629  0.8662 -0.3528  0.3482  1.1371 -0.3339 -1.4724  0.7296\n",
      "\n",
      "Columns 10 to 11 \n",
      "-0.5666  0.4016\n",
      "-0.1312 -0.6368\n",
      "[torch.FloatTensor of size 2x12]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 4)\n",
    "print(x)\n",
    "print(x.view(2, 12)) # Reshape to 2 rows, 12 columns\n",
    "print(x.view(2, -1)) # Same as above.  If one of the dimensions is -1, its size can be inferred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Computation Graphs and Automatic Differentiation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝 프레임워크의 가장 큰 장점인 자동 미분 기능을 사용하려면 텐서를 Variable이라고 클래스로 래핑해야 함. (<strong>Variable</strong>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1\n",
      " 2\n",
      " 3\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "\n",
      " 5\n",
      " 7\n",
      " 9\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "<AddBackward1 object at 0x7fc244c68198>\n"
     ]
    }
   ],
   "source": [
    "# Variables wrap tensor objects\n",
    "x = Variable( torch.Tensor([1., 2., 3]), requires_grad=True )\n",
    "# You can access the data with the .data attribute\n",
    "print(x.data)\n",
    "\n",
    "# You can also do all the same operations you did with tensors with Variables.\n",
    "y = Variable( torch.Tensor([4., 5., 6]), requires_grad=True )\n",
    "z = x + y\n",
    "print(z.data)\n",
    "\n",
    "# BUT z knows something extra.\n",
    "print(z.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 21\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "<SumBackward0 object at 0x7fc244c6d3c8>\n"
     ]
    }
   ],
   "source": [
    "# Lets sum up all the entries in z\n",
    "s = z.sum()\n",
    "print(s)\n",
    "print(s.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s.backward() # calling .backward() on any variable will run backprop, starting from it.\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ s = \\overbrace{x_0 + y_0}^\\text{$z_0$} + \\overbrace{x_1 + y_1}^\\text{$z_1$} + \\overbrace{x_2 + y_2}^\\text{$z_2$} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{\\partial s}{\\partial x_0} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. torch Module "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주요 모듈 : nn.Linear (Affine Maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ f(x) = Ax + b $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.0114 -0.5978 -1.0424\n",
      "-0.0682 -0.4090  0.1108\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lin = nn.Linear(5, 3) # maps from R^5 to R^3, parameters A, b\n",
    "data = Variable( torch.randn(2, 5) ) \n",
    "print(lin(data)) # (2x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주요 모듈 : 비선형 함수들 (Non-Linearities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-1.0246 -1.0300\n",
      "-1.0129  0.0055\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  0.0000  0.0000\n",
      "  0.0000  5.5350\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "Variable containing:\n",
      "-0.7717 -0.7739\n",
      "-0.7670  0.0055\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "Variable containing:\n",
      " 0.2641  0.2631\n",
      " 0.2664  0.5014\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = Variable( torch.randn(2, 2) )\n",
    "print(data)\n",
    "print(F.relu(data))\n",
    "print(F.tanh(data))\n",
    "print(F.sigmoid(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주요 모듈 : Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.9347\n",
      "-0.9882\n",
      " 1.3801\n",
      "-0.1173\n",
      " 0.9317\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "Variable containing:\n",
      " 0.0481\n",
      " 0.0456\n",
      " 0.4867\n",
      " 0.1089\n",
      " 0.3108\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "-3.0350\n",
      "-3.0885\n",
      "-0.7201\n",
      "-2.2176\n",
      "-1.1686\n",
      "[torch.FloatTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Softmax is also in torch.functional\n",
    "data = Variable( torch.randn(5) )\n",
    "print(data)\n",
    "print(F.softmax(data))\n",
    "print(F.softmax(data).sum()) # Sums to 1 because it is a distribution!\n",
    "print(F.log_softmax(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이토치는 모델을 클래스처럼 다룰 수 있는데, torch.nn.Module을 상속받아서 부모 클래스를 초기화하면 된다. <br>\n",
    "선정의 된 함수 forward에 Variable을 인자 값으로 보내면 forward 계산을 하면서 Parameter와의 backward 연결을 알아서 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class simpleNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(simpleNN, self).__init__() # 부모 클래스까지 초기화(부모 클래스 생성자 호출)\n",
    "        self.linear = nn.Linear(2,2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        return self.sigmoid(self.linear(inputs))\n",
    "#         return F.sigmoid(self.linear(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snn = simpleNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simpleNN(\n",
       "  (linear): Linear(in_features=2, out_features=2)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('linear.weight', Parameter containing:\n",
      "-0.6167  0.5950\n",
      "-0.1340  0.1427\n",
      "[torch.FloatTensor of size 2x2]\n",
      ")\n",
      "('linear.bias', Parameter containing:\n",
      " 0.0262\n",
      "-0.4506\n",
      "[torch.FloatTensor of size 2]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for param in snn.named_parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.3892 -0.0115\n",
       "[torch.FloatTensor of size 1x2]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = Variable(torch.randn(1,2))\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.4451  0.3765\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = snn(inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(snn.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dampening': 0,\n",
       "  'lr': 0.01,\n",
       "  'momentum': 0,\n",
       "  'nesterov': False,\n",
       "  'params': [Parameter containing:\n",
       "   -0.6167  0.5950\n",
       "   -0.1340  0.1427\n",
       "   [torch.FloatTensor of size 2x2], Parameter containing:\n",
       "    0.0262\n",
       "   -0.4506\n",
       "   [torch.FloatTensor of size 2]],\n",
       "  'weight_decay': 0}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
