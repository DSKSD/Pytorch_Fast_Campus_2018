{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchtext\n",
    "import nltk\n",
    "from konlpy.tag import Kkma\n",
    "from torchtext.data import Field, Iterator, BucketIterator, TabularDataset\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대화 모델 더미 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kor_tagger = Kkma()\n",
    "\n",
    "kor_tagger = kor_tagger.morphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SOURCE = Field(tokenize=kor_tagger,use_vocab=True,init_token=\"<s>\",eos_token=\"</s>\",lower=True, include_lengths=True, batch_first=True)\n",
    "TARGET = Field(tokenize=kor_tagger,use_vocab=True,init_token=\"<s>\",eos_token=\"</s>\",lower=True, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = TabularDataset(\n",
    "                                   path=\"data/dsksd_chat.txt\",\n",
    "                                   format='tsv', # \\t로 구분\n",
    "                                   #skip_header=True, # 헤더가 있다면 스킵\n",
    "                                   fields=[('inputs',SOURCE),('targets',TARGET)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SOURCE.build_vocab(train_data)\n",
    "TARGET.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316 272\n"
     ]
    }
   ],
   "source": [
    "print(len(SOURCE.vocab),len(TARGET.vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterator vs BucketIterator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = train_loader = Iterator(\n",
    "    train_data, batch_size=32, device=-1, # device -1 : cpu, device 0 : 남는 gpu\n",
    "    sort_key=lambda x: len(x.inputs),sort_within_batch=True,repeat=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader_bucket = BucketIterator(\n",
    "    train_data, batch_size=32, device=-1, # device -1 : cpu, device 0 : 남는 gpu\n",
    "    sort_key=lambda x: len(x.inputs),sort_within_batch=True,repeat=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for batch in train_loader: # Iterator\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs, lengths = batch.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for batch in train_loader_bucket:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs, lengths = batch.inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PackedSequence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "패딩이 들어간 시퀀스의 value를 저장하고, Computational graph가 생성되지 않게 한다.<br>\n",
    "즉, 연산에 제로 패딩의 인풋이 영향을 미치지 못하도록 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "E = 50\n",
    "H = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embed = nn.Embedding(len(SOURCE.vocab),E)\n",
    "rnn = nn.GRU(E,H,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 12, 50])\n"
     ]
    }
   ],
   "source": [
    "embedded = embed(inputs)\n",
    "print(embedded.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "packed = pack_padded_sequence(embedded,lengths.tolist(),batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=Variable containing:\n",
       " 1.6234e-02 -1.8424e+00  1.4331e+00  ...   6.8099e-02  9.2081e-01 -1.5433e+00\n",
       " 1.6234e-02 -1.8424e+00  1.4331e+00  ...   6.8099e-02  9.2081e-01 -1.5433e+00\n",
       " 1.6234e-02 -1.8424e+00  1.4331e+00  ...   6.8099e-02  9.2081e-01 -1.5433e+00\n",
       "                ...                   ⋱                   ...                \n",
       " 9.4805e-01  1.6872e+00 -2.5527e+00  ...  -2.2250e-01  1.4441e-01 -8.6105e-01\n",
       " 9.4805e-01  1.6872e+00 -2.5527e+00  ...  -2.2250e-01  1.4441e-01 -8.6105e-01\n",
       " 9.4805e-01  1.6872e+00 -2.5527e+00  ...  -2.2250e-01  1.4441e-01 -8.6105e-01\n",
       "[torch.FloatTensor of size 323x50]\n",
       ", batch_sizes=[32, 32, 32, 32, 32, 32, 32, 32, 32, 23, 9, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output, hidden  = rnn(packed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=Variable containing:\n",
       "-0.0118 -0.1620 -0.1552  ...   0.0367 -0.1304 -0.1384\n",
       "-0.0118 -0.1620 -0.1552  ...   0.0367 -0.1304 -0.1384\n",
       "-0.0118 -0.1620 -0.1552  ...   0.0367 -0.1304 -0.1384\n",
       "          ...             ⋱             ...          \n",
       " 0.0992 -0.3912  0.3775  ...  -0.1070  0.0772  0.0654\n",
       " 0.0239 -0.1329  0.3856  ...  -0.0854 -0.0348  0.0602\n",
       " 0.0920 -0.5095  0.3166  ...  -0.3060  0.0027 -0.0288\n",
       "[torch.FloatTensor of size 323x100]\n",
       ", batch_sizes=[32, 32, 32, 32, 32, 32, 32, 32, 32, 23, 9, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unPack "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packing된 시퀀스를 다시 원래대로 되돌리면서 제로패딩 위치에는 특정값(디폴트 = 0.0)으로 채운다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output, output_lengths = pad_packed_sequence(output,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 12, 100])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "( 0 ,.,.) = \n",
       " -0.0118 -0.1620 -0.1552  ...   0.0367 -0.1304 -0.1384\n",
       " -0.1827 -0.2275 -0.1667  ...  -0.2092  0.1295 -0.0127\n",
       " -0.0726 -0.2754  0.0067  ...  -0.0280  0.1246  0.1970\n",
       "           ...             ⋱             ...          \n",
       " -0.0685 -0.0039  0.3231  ...   0.2204  0.0366 -0.1132\n",
       "  0.1538 -0.0491  0.2829  ...   0.1999  0.0752  0.0579\n",
       "  0.0992 -0.3912  0.3775  ...  -0.1070  0.0772  0.0654\n",
       "\n",
       "( 1 ,.,.) = \n",
       " -0.0118 -0.1620 -0.1552  ...   0.0367 -0.1304 -0.1384\n",
       " -0.2294 -0.3520 -0.3003  ...   0.0351 -0.4487 -0.1060\n",
       " -0.1560 -0.3315 -0.1301  ...   0.0680 -0.1750  0.1779\n",
       "           ...             ⋱             ...          \n",
       " -0.0379  0.5724  0.4190  ...   0.2257  0.0284 -0.1854\n",
       "  0.0095  0.3871  0.2790  ...   0.1705 -0.2041  0.0232\n",
       "  0.0239 -0.1329  0.3856  ...  -0.0854 -0.0348  0.0602\n",
       "\n",
       "( 2 ,.,.) = \n",
       " -0.0118 -0.1620 -0.1552  ...   0.0367 -0.1304 -0.1384\n",
       "  0.1266 -0.2595 -0.0393  ...   0.1334  0.0193 -0.2565\n",
       "  0.0180 -0.4487  0.1233  ...   0.2001 -0.1435 -0.0637\n",
       "           ...             ⋱             ...          \n",
       "  0.0604 -0.3655  0.2392  ...  -0.2587 -0.1783 -0.3187\n",
       "  0.1913 -0.2728  0.2045  ...  -0.1860 -0.0752 -0.1099\n",
       "  0.0920 -0.5095  0.3166  ...  -0.3060  0.0027 -0.0288\n",
       "... \n",
       "\n",
       "(29 ,.,.) = \n",
       " -0.0118 -0.1620 -0.1552  ...   0.0367 -0.1304 -0.1384\n",
       " -0.0924 -0.1311  0.1266  ...   0.2958  0.1667  0.0527\n",
       " -0.3628 -0.0357  0.0452  ...   0.1484  0.0714  0.0935\n",
       "           ...             ⋱             ...          \n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "\n",
       "(30 ,.,.) = \n",
       " -0.0118 -0.1620 -0.1552  ...   0.0367 -0.1304 -0.1384\n",
       "  0.3725  0.0296 -0.0069  ...   0.0075 -0.1759 -0.1169\n",
       "  0.1992 -0.3527  0.0469  ...  -0.0443  0.0036  0.1631\n",
       "           ...             ⋱             ...          \n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "\n",
       "(31 ,.,.) = \n",
       " -0.0118 -0.1620 -0.1552  ...   0.0367 -0.1304 -0.1384\n",
       " -0.1481 -0.0509  0.2151  ...   0.1289  0.0093 -0.3345\n",
       "  0.0106 -0.0639 -0.1075  ...   0.2701  0.2208 -0.2153\n",
       "           ...             ⋱             ...          \n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "[torch.FloatTensor of size 32x12x100]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
