{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchtext\n",
    "import nltk\n",
    "from konlpy.tag import Mecab\n",
    "from torchtext.data import Field,BucketIterator, TabularDataset, Dataset\n",
    "import os\n",
    "DATA_PATH = os.environ['DATA_PATH']\n",
    "tagger = Mecab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 로드 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naver sentiment movie corpus v1.0 (https://github.com/e9t/nsmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = 0 if USE_CUDA else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_under_five(toknized):\n",
    "    \"\"\"\n",
    "    모델에서 5-gram 단위 필터를 사용하기 때문에\n",
    "    5-gram이 안되는 문장에 <pad>로 채워준다\n",
    "    \"\"\"\n",
    "    if len(toknized) < 5:\n",
    "        toknized.extend([\"<pad>\"]*(5-len(toknized)))\n",
    "    return toknized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEXT = Field(tokenize=tagger.morphs,lower=True,include_lengths=False,batch_first=True,preprocessing=pad_under_five)\n",
    "LABEL = Field(sequential=False,use_vocab=True,unk_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data = TabularDataset.splits(path=DATA_PATH+'/NSMC/',\n",
    "                                                  train='ratings_train.txt',test='ratings_test.txt',\n",
    "                                                  format='tsv',\n",
    "                                                  skip_header=True,\n",
    "                                                  fields=[('id',None),('text',TEXT),('label',LABEL)],\n",
    "                                                  filter_pred = lambda x: True if len(x.text) > 1 else False) # 토큰 레벨 문장의 길이가 1 이상인 경우만 허용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data,min_freq=2)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29974 2\n"
     ]
    }
   ],
   "source": [
    "print(len(TEXT.vocab),len(LABEL.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader, test_loader = BucketIterator.splits((train_data,test_data),sort_key=lambda x:len(x.text), sort_within_batch=True,\n",
    "                                           repeat=False,shuffle=True,\n",
    "                                           batch_size=32,device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO : 모델링 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class  CNNClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, output_size, kernel_dim=100, kernel_sizes=(3, 4, 5), dropout=0.5):\n",
    "        super(CNNClassifier,self).__init__()\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        self.convs = nn.ModuleList([nn.Conv1d(1, kernel_dim, embedding_dim * K, stride=embedding_dim) for K in kernel_sizes])\n",
    "\n",
    "        # kernal_size = (K,D) \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(len(kernel_sizes) * kernel_dim, output_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        # TODO : 완성하시오"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 트레이닝 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCH = 5\n",
    "BATCH_SIZE = 32\n",
    "EMBED = 300\n",
    "KERNEL_SIZES = [3,4,5]\n",
    "KERNEL_DIM = 100\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = CNNClassifier(len(TEXT.vocab), EMBED, 1, KERNEL_DIM, KERNEL_SIZES)\n",
    "\n",
    "if USE_CUDA:\n",
    "    model = model.cuda()\n",
    "    \n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[3], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 mean_loss : 0.754 , lr : 0.00100\n",
      "epoch : 0 mean_loss : 0.524 , lr : 0.00100\n",
      "epoch : 0 mean_loss : 0.434 , lr : 0.00100\n",
      "epoch : 0 mean_loss : 0.403 , lr : 0.00100\n",
      "epoch : 0 mean_loss : 0.391 , lr : 0.00100\n",
      "epoch : 1 mean_loss : 0.574 , lr : 0.00100\n",
      "epoch : 1 mean_loss : 0.329 , lr : 0.00100\n",
      "epoch : 1 mean_loss : 0.338 , lr : 0.00100\n",
      "epoch : 1 mean_loss : 0.337 , lr : 0.00100\n",
      "epoch : 1 mean_loss : 0.325 , lr : 0.00100\n",
      "epoch : 2 mean_loss : 0.314 , lr : 0.00100\n",
      "epoch : 2 mean_loss : 0.278 , lr : 0.00100\n",
      "epoch : 2 mean_loss : 0.286 , lr : 0.00100\n",
      "epoch : 2 mean_loss : 0.295 , lr : 0.00100\n",
      "epoch : 2 mean_loss : 0.295 , lr : 0.00100\n",
      "epoch : 3 mean_loss : 0.264 , lr : 0.00010\n",
      "epoch : 3 mean_loss : 0.226 , lr : 0.00010\n",
      "epoch : 3 mean_loss : 0.218 , lr : 0.00010\n",
      "epoch : 3 mean_loss : 0.218 , lr : 0.00010\n",
      "epoch : 3 mean_loss : 0.211 , lr : 0.00010\n",
      "epoch : 4 mean_loss : 0.031 , lr : 0.00010\n",
      "epoch : 4 mean_loss : 0.196 , lr : 0.00010\n",
      "epoch : 4 mean_loss : 0.199 , lr : 0.00010\n",
      "epoch : 4 mean_loss : 0.199 , lr : 0.00010\n",
      "epoch : 4 mean_loss : 0.195 , lr : 0.00010\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(EPOCH):\n",
    "    losses=[]\n",
    "    scheduler.step()\n",
    "    for i,batch in enumerate(train_loader):\n",
    "        inputs, targets = batch.text, batch.label.float()\n",
    "        if USE_CUDA:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "        model.zero_grad()\n",
    "        preds = model(inputs)\n",
    "        loss = loss_function(preds.squeeze(1),targets)\n",
    "        losses.append(loss.data[0])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print(\"epoch : %d mean_loss : %.3f , lr : %.5f\" % (epoch,np.mean(losses), scheduler.get_lr()[0]))\n",
    "            losses=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정량적 테스트 : Accruacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.45\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "num_hit=0\n",
    "for i,batch in enumerate(test_loader):\n",
    "    inputs, targets = batch.text, batch.label.float()\n",
    "    if USE_CUDA:\n",
    "        inputs = inputs.cuda()\n",
    "        targets = targets.cuda()\n",
    "    inputs = inputs\n",
    "    targets = targets\n",
    "    preds = model(inputs)\n",
    "    preds = preds.round()\n",
    "    num_hit+=torch.eq(preds.squeeze(),targets.squeeze()).sum().data[0]\n",
    "\n",
    "print(num_hit/len(test_data)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정성적 테스트 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "헐 진짜 개별로다.. \u001b[1;01;31m부정\u001b[0m\n",
      "진짜 너무 재밌는 영화다 오랜만에 \u001b[1;01;36m긍정\u001b[0m\n",
      "오..이건 진짜 봐야함 \u001b[1;01;36m긍정\u001b[0m\n",
      "진짜 쓰레기 같은 영화 \u001b[1;01;31m부정\u001b[0m\n",
      "노잼 \u001b[1;01;31m부정\u001b[0m\n",
      "존잼 \u001b[1;01;36m긍정\u001b[0m\n",
      "꾸울잼 \u001b[1;01;36m긍정\u001b[0m\n",
      "핵노잼 \u001b[1;01;31m부정\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "test_inputs = [\"헐 진짜 개별로다..\", \"진짜 너무 재밌는 영화다 오랜만에\",\"오..이건 진짜 봐야함\", \"진짜 쓰레기 같은 영화\",\"노잼\",\"존잼\",\"꾸울잼\",\"핵노잼\"]\n",
    "\n",
    "for test_input in test_inputs:\n",
    "    tokenized = tagger.morphs(test_input)\n",
    "    tokenized = pad_under_five(tokenized)\n",
    "    input_ = TEXT.numericalize([tokenized],device=-1)\n",
    "    if USE_CUDA: input_ = input_.cuda()\n",
    "\n",
    "    prediction = model(input_)\n",
    "    prediction = prediction.round()\n",
    "    prediction = \"긍정\" if prediction.data[0][0] == 1 else \"부정\"\n",
    "    if prediction==\"긍정\":\n",
    "        print(test_input,\"\\033[1;01;36m\" + prediction + \"\\033[0m\")\n",
    "    else:\n",
    "        print(test_input,\"\\033[1;01;31m\" + prediction + \"\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
